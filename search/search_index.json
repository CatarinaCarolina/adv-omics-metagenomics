{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Biosb Computational Metagenomics","text":"<p>This course teaches state-of-the-art computational methods for the analysis of metagenome data. Lectures will be combined with hands-on computer sessions using Linux command line tools, Galaxy and R to practice use of the methods on real data.</p> <p>The course will start with foundational knowledge and skills in experimental design, sequencing technologies, quality control, assembly and binning. Subsequently, we will look at various taxonomic assignment algorithms and the use of metagenomic databases such as MGnify. To compare metagenomic features between samples and conditions, we will study various statistical techniques, including differential abundance/expression analysis, association analysis with metadata and causal inference. Finally, we will explore several levels of functional metagenome annotation, including the identification of biosynthetic gene clusters, virulence factors and phages, and community-level metabolic modeling. We will close the course with a keynote lecture on the use of metatranscriptomics to analyse gene expression patterns in microbiomes.</p> <p>After the course, the slides of the presentations and the practicals will remain available for future reference. Software packages used are freeware.</p> <p>For more info on the course see https://www.dtls.nl/courses/computational-metagenomics/</p>"},{"location":"data-processing/assembly/","title":"Assembly","text":"<p>Learning objectives</p> <ul> <li>Being able to create an assembly with megahit</li> <li>Assess the quality of the assembly</li> </ul> <p>Now that our reads are quality trimmed and ready to go is time to start the assembly. We can use megahit:</p> <pre><code>megahit --12 sample_0.nophix.fastq.gz,sample_1.nophix.fastq.gz,sample_2.nophix.fastq.gz,sample_3.nophix.fastq.gz,sample_4.nophix.fastq.gz,sample_5.nophix.fastq.gz \\\n        -t 16 \\\n        -o megahit_assembly_meta \\\n        --presets meta-sensitive\n</code></pre> <p>This command would take around 50 minutes to complete, to speed up things we pre-assembled the data which is available in the precomputed/assembly/ folder. </p> <p>Feel free to inspect the contents of the folder by using</p> <pre><code>ls -lh precomputed/assembly/\n</code></pre> <p>You will notice the final.contigs.fa file which contains the assembly</p> <p>Now, we want to find out how well or poorly our assembly went. For this, we use quast, a tool to generate an assembly report.</p> <pre><code>quast precomputed/assembly/final.contigs.fa -o quast/\n</code></pre> <p>Then, we inspect the output from quast. </p> <pre><code>less quast/report.txt\n</code></pre> <p>Not bad! We know our metagenome is not too large and if we care about contiguity, contigs above 5kb represent most of our community</p>"},{"location":"data-processing/binning/","title":"Binning","text":"<p>Learning objectives</p> <ul> <li>Extract individual genomes from an assembly</li> </ul> <p>Next, we want to map the reads back on the assembly to see how the coverage for each contig changed across samples:</p> <pre><code>bwa mem precomputed/assembly/final.contigs.fa \\\n        reads/sample_0.fq.gz \\\n        -o bam/sample_0.bam \\\n        -t 32\n</code></pre> <p>Here, we won\u2019t run it for all samples to save time and space, you will find the bam files in the precomputed/bam/ folder. </p> <p>Question</p> <p>Feel free to inspect the content as done before, do you notice something particular?</p> <p>Now, many tools need bam files to be sorted in order to work. Therefore, we will use samtools sort to do that.</p> <pre><code>samtools sort precomputed/bam/sample_0.bam -o bam/sample_0.sorted.bam\n</code></pre> <p>The sorted bam files can also be index, so other tools can quickly extract alignments</p> <pre><code>for bam in *.sorted.bam; do samtools index $bam; done\n</code></pre> <p>We can first get an idea if the different genomes can be seperated by gc-content and coverage. With Blobtools the coverage and gc-content of the contigs can be plotted and visualy bins or blobs can be detected</p> <pre><code>wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz\ntar zxvf taxdump.tar.gz\nblobtools nodesdb --nodes db/nodes.dmp --names db/names.dmp\n\nblobtools create -i data/precomputed/assembly/final.contigs.fa -b data/precomputed/bam/sample_0.sorted.bam -b data/precomputed/bam/sample_1.sorted.bam -b data/precomputed/bam/sample_2.sorted.bam -b data/precomputed/bam/sample_3.sorted.bam -b data/precomputed/bam/sample_4.sorted.bam -b data/precomputed/bam/sample_5.sorted.bam\n\nblobtools view -i blobDB.json\nblobtools plot -i blobDB.json\n</code></pre> <p>Question</p> <p>Take a look at the <code>blobDB.json.bestsum.phylum.p8.span.100.blobplot.bam0.png</code> file. How many large genome bins can you detect? How is this for the other files?</p> <p>Now, we will create a depth table, which can be used by binning tools to identify genomic entities (contigs, here) that have similar coverage across samples.</p> <pre><code>jgi_summarize_bam_contig_depths --outputDepth depth.tsv bam/sample_0.sorted.bam bam/sample_1.sorted.bam bam/sample_2.sorted.bam bam/sample_3.sorted.bam bam/sample_4.sorted.bam bam/sample_5.sorted.bam\n</code></pre> <p>Now, we can run metabat to find our bins:</p> <pre><code>metabat2 -a depth.tsv -i precomputed/assembly/final.contigs.fa.gz -o binned_genomes/bin\n</code></pre> <p>After this is done, we will now try and figure out how good are our bins, we will use checkm. First we create a set of lineage specific markers for bacterial genomes:</p> <pre><code>checkm taxon_set domain Bacteria checkm_taxon_bacteria\n</code></pre> <p>Now, it\u2019s time to find out the completeness of your binned genomes:</p> <pre><code>checkm analyze -x fa checkm_taxon binned_genomes/ checkm_bac/\n</code></pre> <p>This created the checkm_bac/ folder with the information on our bins, to interpret the results we use checkm qa:</p> <pre><code>checkm qa checkm_taxon checkm_bac/\n</code></pre> <p>Question</p> <p>What does it mean? How can we interpret this?</p> <p>Now, we will let checkm predict the taxonomy of the bins and evaluate their completeness.</p> <pre><code>checkm lineage_wf -t 8 -x fa binned_genomes/ checkm_taxonomy/\n</code></pre> <p>This command will take some time but it will give us a detailed breakdown of each genome predicted taxonomy and completeness.</p> <p>With the bam files, a coverage file can also be created with the tool CoverM</p> <pre><code>coverm contig -b data/precomputed/bam/sample_*.sorted.bam -m mean -t 16 -o coverage.tsv\n</code></pre>"},{"location":"data-processing/cave-expedition/","title":"Cave expedition","text":"<p>Learning objectives</p> <ul> <li>Explore binning results from biofilm metagenomes in a greenhouse gas-emitting cave.</li> <li>Seek evidence identifying the primary consumers (CO2 &amp; CH4) within this extreme environment.</li> </ul> <p> (a) General overview of the cave. The dashed line in panel a marks the stable gaseous chemocline between the volcanic gases (below the chemocline) and atmospheric air (above the chemocline). (b) Detailed images of the cave biofilms. (c) A closer look on the biofilm where mark 7 shows the bare cave wall after biofilm sampling.</p> <p>Watch the \"Sulfur Cave\" video to see bubbles drifting along the invisible stream of greenhouse gases (for fun).</p> <p>Precomputed data is stored in the /data/precomputed/cave_data folder, which contains the following: 1) Co-assembly of three samples (two from biofilm and one from the laboratory), 2) Depth table and 3) Binning results</p> <p>Exercise</p> <ul> <li>Analyze the microbial bins to identify which organism is utilizing CH\u2084 (methane) for growth. What is the taxonomic classification of this organism? Investigate the presence of relevant gene clusters responsible for methane metabolism.</li> <li>Investigate whether it is common for organisms within the identified taxon to utilize CH\u2084 for growth. If not, outline the steps and analyses you would perform to confirm and demonstrate this metabolic capability.</li> <li>Perform a similar investigation to identify which organism is fixing CO\u2082 for growth. What is the taxonomy of this organism, and what genes are involved in CO\u2082 fixation?</li> </ul> Tip 1: general directions <ul> <li>Assess bin quality using CheckM to evaluate completeness and contamination levels.</li> <li>Assign taxonomies to the bins with GTDB-Tk for precise classification.</li> <li>Predict open reading frames (ORFs) using Prodigal and functionally annotate the bins through EggNOG for a deeper understanding of their metabolic capabilities.</li> </ul> Tip 2 <ul> <li>Investigate the gene annotation for methane monooxygenase and reductive TCA cycle and analyze the surrounding genomic regions to identify nearby genes and their associated protein functions.</li> <li>Calculate the abundance of each bin by integrating the depth table with the binning results (use python/R).</li> </ul>"},{"location":"data-processing/intro/","title":"Introduction","text":""},{"location":"data-processing/intro/#dataset-explanation","title":"Dataset explanation","text":"<ul> <li>In the practical you will go from raw reads to taxonomical characterization of metagenome assembled genomes</li> <li>In this mock experiment we have a small diverse synthetic rhizosphere community</li> <li>We expose the plant to fungal chitin and we expect the plant to respond to this treatment by modulating the microbial community it associates with in the rhizosphere</li> <li>Can you find out how the microbial community adapts?</li> </ul>"},{"location":"data-processing/intro/#slides","title":"Slides","text":"<p> Download the presentation (2022)  Download the presentation (2024)</p>"},{"location":"data-processing/quality-control/","title":"Quality Control","text":"<p>Learning objectives</p> <ul> <li>Understanding the FastQ format</li> <li>Interpret FastQC reports</li> <li>Create high quality reads by trimmign and filtering with FastP and BBduk</li> </ul>"},{"location":"data-processing/quality-control/#fastq-format","title":"FastQ format","text":"<p>First let's take a look at the data</p> <pre><code>zcat /data/reads/sample_0.fq.gz | head\n</code></pre> The output looks like this <pre><code>@gi|1184849861|gb|KY629563.1|-34525/1\nCTGATCAACGTGGGAATGAACATGGAGCAGAGCGGCCAGTGTCTCAACCTGTGCTCCGCCTTCATGCACTCTCGCGGCGCCTTCAAGCCCGGCGACATCGACGTGGAAATTTTCACCATGCCCACCAAGTTCGGGCGCGTCAGCACCACG\n+\nDDDGGEG*DIIGH?KKHJGHGKKKJKKJJ9JDK=JKFKKGJHIKHEIJJJKKGIHKGDE1DKA&gt;KEGBEEEBGI?BBEGHEEEFEEE9ED;FCB3BEEDCBEE5EEC'CA$E9EEEAEEEFEE?FFCEEE;$EE)DBCDEEDDECAAE'$\n@gi|1184849861|gb|KY629563.1|-34523/1\nGCCTTTGTCGGGTAAGGGGTGTGGCCCTCCTCCCGACAAGGCGGGCCACGGTTCGCCAGCGAACTAGGTCGGGGAGCTGGGAAGGAGCCGGAATCGGGTGGCCCCAATTTCGGGGAGAGGTTTGGGCGTCAGCCGCCCGGAAGCTCGTCG\n+\nDDDE2GGGIIIIIKKJKHJKEDJ=AIHKKHKJKKKKJHBIE$KJJJCEKJB=JH@JKEHKGEEEEDAJECDGC?EIFEBEDDF6FGEEDEE$FBDCEEA@EE$4EE$E??CDE?ED;CCDE1DEBE;ECC$?$$AEDA;EDD@$EEDE=F\n@gi|1184849861|gb|KY629563.1|-34521/1\nAGACCGAGCCCTTCCTTATAGTGGATTTCTCCGGTTCCGTCAACCAAATTTGCAGTAATGCGGGAGCGACGCTTCCACGAAATGGTCACTGTCCCGTCCACCTCGGAGAGCTTTACGCTTTCCGGTGTGTAGGGCTTGAGATCGATCGAT\n</code></pre> <p>There is a pattern that is repeated every 4 lines. This is the FASTQ format. It follows this structure:</p> Line Description 1 Always begins with '@' and then information about the read 2 The actual DNA sequence 3 Always begins with a '+' and sometimes the same info in line 1 4 Has a string of characters which represent the quality scores; must have same number of characters as line 2 <p>The fourth line shows the quality of the read. To make the sequence and the qaility align well, the numerical score is converted into a code where each individual character represents the numerical quality of an individual nucleotide, following this scheme:</p> <p>FASTQ quality encoding</p> <pre><code>    Quality encoding: !\"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJ\n                    |         |         |         |         |\n    Quality score:    01........11........21........31........41\n</code></pre> <p>NextSeq and NovaSeq data often contains poly-g tails. Let's check if this also is the case for our simulated input</p> <pre><code>$ zcat /data/reads/sample_0.fq.gz | grep -E \"GGGGGGGGGGGGGGGGGG$\"\n</code></pre> <p>This search does not retun any hits. But often the end of the sequences contain stretches of poly-g. Below is an example how poly-g tails look like in Novaseq data.</p> Sequence data with poly-g tails <pre><code>GGCCAGGACCACGCGGTGGAGCAGCGCGCCGCGGCGCCGGGCGCGCTTGACGACCAGTCTCTTATAAACATATCCCAGCCCACGAGACCACCAGTTGCATCTCGTATTCCGTCTTATGCTTGTATATTGGGGGGGGGGGGGGGGGGGGGGG\nGAGTCGATCGAGGAGATGAAGCACGCGGAGAAGGTCATTCACCGCATCCTCTACTTCGATGCTGTCTCTTATACACATCCCGAGCCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAAGGGGGGGGGGGGGGGGGGG\nGGCCCGTGCAGTTCGAGATCATCTCCGAGCCCACGAGACGACCGGGTGCTTGGCGGGAGCGGCGGGGTGGTTTTATCTTCGTGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\nGGGCGGCAACGCCGACACCTACCAGCTACAGCAGACGGTGCGCCGCACCATCGGCCGCTGGGTCGGCGGCCGGCTGCGCCGCCGTCCCAAGATAATCCCGGTGGTGGGGGGGGGTGGTTGGGGGGGTTGTGGGGGGGGGGGGGGGGGGGGG\nGGTAGGGCCGCTCGAGAAGCTCGCACAGCATGCGGCCGAATTCGCGGTACATGCATACGTTGACGTCGGCGGGGGGGGGGGGGGGGGGAGAGCACCGGGGGGCGCACAGGGCGGCCGGGTGGGGGTCGTGGTGGGGGGGGGGGGGGGGGGG\nGGGGAGGAGGGAGACGCGCCCGCGGGCGTGCCCGCCGCCGCGGCGATGCCCTTGAAGGCCGCTGGTGTGTCCTTCAGCGCCTGCGCCGCGAGTTCGCCGAACTGCTGCGTCAACGCGCCCCACCACTGCTGCGGGGGGGGGGGGGGGGGGG\nGTACCCGAGCCGCTCCGCGTGCCGCCGGACCTCCGACGCGTGAGGCCCGGAGCCGGTCGCTGACCAGAGGGCCAGGCCGAAGCGATGGGGAGTGGTCGCGACGAACCCGCAGCGCTGTCCGGCGGCGGGGGGGGGGGGGGGGGGGGGGGGG\nGAAGGTGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCGGGGGGGGGGGGGGGCGGGGGCGGGGGGGGGGGGGGGGGGGGGGGGGGGG\nGCGCCACGCCGAGCACCGACGGCATCATCGGCACCCACACGCCGTGTGTGAACCTGTCTCTTATACACATCTCCGAGCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAATGGGGGGGGGGGGGGGGGGGGGGGGGG\nCTCTTCATCCGTTCCGGCGCCTGCATCCATTCCCGCGGCGCCGGTTGGCGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n</code></pre>"},{"location":"data-processing/quality-control/#fastqc-reports","title":"FastQC reports","text":"<p>Let's check the quality of the data with FastQC before quality filtering:</p> <pre><code>mkdir fastqc_untrimmed_reads\nfastqc --threads 8 /data/reads/sample_0.fq.gz -o fastqc_untrimmed_reads/\n</code></pre> <p>Question</p> <p>Open the FastqQC report <code>fastqc_untrimmed_reads//sample_0_fastqc.html</code></p>"},{"location":"data-processing/quality-control/#quality-trimming-and-filtering","title":"Quality trimming and filtering","text":"<p>Because NovaSeq and NextSeq from Illumina contain often poly-g tails, it is good to use a trimming tool that can detect poly-g tails. Fastp can do that. We keep the defaults like they are, but specify we have interleaved input data. In case you have R1 and R2 file for each sample, you need to enable adapter detection with the <code>--detect_adapter_for_pe</code> flag. Execute fastp with this command:</p> <pre><code>fastp -i /data/reads/sample_0.fq.gz \\\n      --stdout \\\n      --interleaved_in \\\n      -q 25 \\\n      --cut_front \\\n      --cut_tail \\\n      --cut_mean_quality 25 \\\n      -l 51 \\\n      --thread 16 \\\n      --trim_poly_g &gt; sample_0.trim.fastq\n</code></pre> <p>Now make a FastQC report again, to see the results of the quality filtering.</p> <pre><code>mkdir fastqc_trimmed_reads\nfastqc --threads 8 sample_0.trim.fastq -o fastqc_trimmed_reads/\n</code></pre> <p>Exercise</p> <ul> <li>Are there any adapter sequences detected?</li> <li>Take a look at the html report</li> </ul>"},{"location":"data-processing/quality-control/#alternative-trimming-with-bbduk","title":"Alternative trimming with bbduk","text":"<p>Alternative trimming with bbduk. Compare poly-g tail filtering, adapter trimming.</p> <pre><code>bbduk.sh in=/data/reads/sample_0.fq.gz  \\\n    out=sample_0.trim.bbduk.fastq.gz \\\n    interleaved=true \\\n    trimpolygright=1 \\\n    qtrim=w trimq=20 \\\n    minlength=51 \\\n    ref=/data/databases/nextera.fa.gz ktrim=r \\\n    stats=bbduk.stats \\\n    t=16\n</code></pre> <p>Question</p> <ul> <li>Create also an FastQC report for the trimming with bbduk </li> <li>What are differences between filtering with fastp and bbduk?</li> </ul>"},{"location":"data-processing/quality-control/#remove-phix-sequences","title":"Remove PhiX sequences","text":"<pre><code>bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz \\\n         in=sample_0.trim.fastq \\\n         interleaved=true \\\n         outu=sample_0.nophix.fastq.gz \\\n         outm=sample_0.phix.fastq.gz \\\n         t=4\n</code></pre> <p>Exercise</p> <ul> <li>How many PhiX sequences are detected?</li> <li>From which samples?</li> <li>Can you confirm the sequences are PhiX?</li> <li>The input data was simulated without adding any PhiX. How could there still PhiX sequences being detected?</li> </ul>"},{"location":"data-processing/quality-control/#from-one-sample-to-many","title":"From one sample to many","text":"<p>From one sample to many</p> <p>Now do a QC for all samples. You can use a for loop for that. For example, fastp can be run like:</p> <pre><code>for file in /data/reads/*.gz; do \\\n    sample=$(basename ${file} .fq.gz);\n    fastp -i $file --stdout --interleaved_in -q 25 --cut_front --cut_tail --cut_mean_quality 25 -l 51 --thread 16 --trim_poly_g &gt; $sample.trim.fastq;\n    bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz in=$sample.trim.fastq interleaved=true outu=$sample.nophix.fastq.gz outm=$sample.phix.fastq.gz t=4;\ndone\n</code></pre>"},{"location":"data-processing/quality-control/#quickly-check-what-is-in-this-metagenome","title":"Quickly check what is in this metagenome","text":""},{"location":"data-processing/quality-control/#sendsketch","title":"Sendsketch","text":"<pre><code>sendsketch.sh --in=sample_0.nophix.fastq.gz threads=4 address=refseq\n</code></pre>"},{"location":"data-processing/quality-control/#sourmash","title":"Sourmash","text":"<p>Note: The sourmash database is not included in the VM because it can't be downloaded at the moment. There is an overview of all prepared databases The 51 kmer set of representative genomes would be a good one to use when available</p> <p>Now try it locally, using sourmash. First create a signature for a sigle sample.</p> <pre><code>sourmash sketch dna -p scaled=10000,k=51 sample_0.nophix.fastq.gz -o sample_0.sig\n</code></pre> <p>Find what is in this metagenome using the <code>gather</code> command:</p> <pre><code>sourmash gather sample_0.sig /data/databases/gtdb-rs207.genomic-reps.dna.k51.lca.json.gz\n</code></pre>"},{"location":"data-processing/quality-control/#kraken","title":"Kraken","text":"<p>Compare with kraken</p> <p>First setup the database</p> <pre><code>mkdir kraken_db\ntar zxvf /data/databases/k2_standard_08gb_20220926.tar.gz -C kraken_db\n</code></pre> <p>Now run kraken2</p> <pre><code>kraken2 --db kraken_db/ --threads 16 --output sample_0.kraken --report sample_0.kraken.report --gzip-compressed --use-names sample_0.nophix.fastq.gz\n</code></pre> <p>Question</p> <p>Take a look at the <code>sample_0.kraken.report</code>. What are the differences in classification compared to sendsketch and sourmash?</p>"},{"location":"functional-annotation/bgcs/","title":"Functional annotation - Biosynthetic gene clusters","text":""},{"location":"functional-annotation/bgcs/#step-1-general-overview-biosynthetic-gene-cluster-identification","title":"Step 1 -General overview: biosynthetic gene cluster identification","text":"<p>Here you can find antiSMASH results for the (simulated) metagenome that you analysed on Monday afternoon. Clicking \u2018Compact view\u2019 helps to get a better overview for a metagenome output like this one.</p> 1.    How many biosynthetic gene clusters (BGCs) did antiSMASH identify? Based on the results, which known compounds do you estimate this microbial community to be able to produce? Hint: take a look at the detailed knownclusterblast results for each cluster that has at least &gt; 50% similarity on the gene level to a known cluster to assess this. Do (almost) all core enzymes encoded in the gene cluster show similarity to those in the reference gene cluster? <p>The bacillibactin, bacilysin, lichenysin and plantazolicin gene clusters look real. Others perhaps.</p> 2.    One gene cluster looks like it is fragmented into two pieces. Which one? What could you do to try to assemble it into one piece? <p>The lichenysin gene cluster. It might be possible to assemble it by studying the assembly graph or using specialized tools such as biosyntheticSPAdes.</p> <p>Using the \u2018loose\u2019 mode (see https://antismash.secondarymetabolites.org/), multiple putative BGCs can be identified by antiSMASH, which need to be analyzed manually to assess their value. Here you can find the antiSMASH results for the same genome, but now using the loose mode to predict more (putative) clusters.</p> 3.    Take a look at some of the \u2018newly added\u2019 BGCs, and specifically look at the smCOG annotations and the knownclusterblast results. Can you identify some clusters that are very probable to encode the biosynthesis of an actual secondary metabolite? And can you find some clusters for which this is very unlikely? Note that some BGCs may be fragmented (visible by a note \u2018Region on contig edge\u2019) and may only show partial similarity to reference BGCs. <p>Region 413.1 might encode a fragment of a real BGC, based on the fact that it lies on a contig edge, and the Knownclusterblast tab shows a match with part of a known BGC. Others are less likely real. Region 1068.1, for example, looks very doubtful, because it comprises only three identified enzyme-coding genes, separated by a large distance. </p>"},{"location":"functional-annotation/bgcs/#step-2-disease-suppressive-metabolites","title":"Step 2 - Disease-suppressive metabolites","text":"<p>Now go back to the original results. Beneficial plant microbiota are sometimes able to protect plants against pathogens, a microbiome-associated phenotype known as disease suppression. One of the BGCs in this metagenome that might play a role for this is found in region 550.1; this BGC shows similarity to the bacilysin BGC from Bacillus velezensis FZB42 (previously known as Bacillus amyloliquefaciens FZB42). Look up the cluster and check out the Knownclusterblast and MIBiG comparison tabs. </p> 4.    Do you think that region 550.1 is likely to encode the production of bacilysin? Why? <p>Only the transporter-encoding gene is missing, and all enzyme-coding genes seem to be similar. So yes, it is likely.</p> 5.    In the knownclusterblast result, click on the MIBiG accession number of the first hit. This will take you to the reference entry of the known bacilysin BGC in the MIBiG repository. Check out the literature references. What do you learn about the biological activity of bacilysin? How might this molecule play a role in pathogen suppression? <p>Bacilysin is known to have antibacterial activity against bacterial phytopathogens such as Xanthomonas.</p> 6.    Just downstream of the putative bacilysin gene cluster, you will find another large operon with many enzyme-coding genes. What do you think this operon might encode? Can you hypothesise a functional reason why these two operons are co-localized in the genome? Check out this paper for some hints (check section 3.4). <p>The paper suggests that bacilysin is produced by biofilm-producing bacilli. They might use it as protective metabolites, and the bacilli might provide double protection to plant roots by forming a protective coat while also producing antimicrobials.</p>"},{"location":"functional-annotation/bgcs/#step-3-peptidic-fragments","title":"Step 3 - Peptidic fragments","text":"<p>Based on a mass spectrometry experiment, an apparently new natural product is identified from the strain. Based on fragmentation analysis, it appears to be a lipopeptide. A two-amino acid-long fragment is retrieved that is reconstructed based on mass shifts from tandem mass spectra, consisting of a valine and a leucine.</p> <p>Peptide natural products can either be produced by multimodular enzymes called nonribosomal peptide synthetases (identified as \u2018NRPS\u2019 by antiSMASH) or through ribosomal synthesis and subsequent posttranslational modification (e.g., lanthipeptides, lasso peptides, thiopeptides, etc.). For both, chemical structure predictions may be provided (see the \u2018NRPS/PKS modules\u2019 or \u2018Lanthipeptide/Lassopeptide\u2019 tabs).</p> 7.    Based on the antiSMASH results, which gene cluster do you think is most likely responsible for the biosynthesis of the peptide? What strategy did you use to find this out? <p>Region 1023.1. Two subsequent predicted amino acid substrates visible in the 'NRPS/PKS modules' tab match the monomers observed from the MS data.</p>"},{"location":"functional-annotation/viromes/","title":"Functional annotation - Viromics","text":"<p>We will now identify viral sequences from metagenomic data. You will be provided with a set of contigs assembled from infant fecal metagenomic samples (<code>/data/precomputed/virome/contigs.fa</code>). Our goals are to:</p> <ol> <li>Determine the viral origin of the contigs (and assign their taxonomy).</li> <li>Estimate the completeness of viral genomes.</li> <li>Predict the potential bacterial host.</li> <li>Functionally annotate each identified virus.</li> </ol> <p>By the end of this exercise, our objective will be to identify the bacteriophage that satisfies all of the following criteria:  </p> <ul> <li>Belongs to the Caudoviricetes class  </li> <li>Is predicted to have a complete genome </li> <li>Is predicted to infect the Clostridium genus  </li> <li>Has the ability to integrate into the bacterial genome  </li> </ul> <p>Note: For this practical, several tools are required for the viral identification and annotation pipeline:  </p> <ul> <li>geNomad </li> <li>CheckV </li> <li>iPHOP </li> </ul> <p>All these tools and the necessary databases have been preinstalled and are ready for you to use.</p>"},{"location":"functional-annotation/viromes/#step-1-initial-virus-discovery","title":"Step 1 - Initial virus discovery","text":"<p>First, we will run geNomad to identify viral sequences in our dataset. We will utilize the <code>--enable-score-calibration</code> option to compute false discovery rates (FDR). For this practical exercise, no specific FDR thresholds will be applied. Further, we will add the <code>--cleanup</code> flag to remove intermediate files and the <code>--disable-find-proviruses</code> option to avoid geNomad performing an initial prunning to remove potential contaminant host regions from proviral sequences (we will do this in the next step with CheckV). </p> <p>Note: The following command takes about 2 minutes. You can also continue with the results in <code>/data/precomputed/virome/genomad_results/</code>. <pre><code>genomad end-to-end \\\n    --enable-score-calibration \\\n    --disable-find-proviruses \\\n    contigs.fa \\\n    geNomad_results \\\n    --cleanup \\\n    /data/databases/genomad/genomad_db/\n</code></pre></p> <p>You can find a description of the geNomad output files here.</p> <p>Look into <code>geNomad_results/contigs_summary/contigs_virus_summary.tsv</code>. </p> 1. How many of the 100 initial contigs are identified as viral? <p>55 contigs.</p> 2. What is the length of the largest viral genome that we have identified? <p>297,029 bases (MGV_98132).</p> 3. Regarding the viral taxonomy, which is the most common viral class among identified viruses? <p>Caudoviricetes.</p> 4. Do we identify any single-stranded DNA virus (ssDNA)? <p>Yes, there are 13 ssDNA (belonging to Monodnaviria realm).     </p> <p>Note: A useful resource where you can find all the information about the viral taxonomy is here.  </p>"},{"location":"functional-annotation/viromes/#step-2-host-contamination-removal-and-quality-check","title":"Step 2 - Host contamination removal and quality check","text":"<p>While geNomad performs well at identifying proviruses from metagenomic data, CheckV is specifically designed to identify host-virus boundaries with high precision. Further, CheckV allows to estimate the completeness of the predicted viral genomes based on their comparison to a database of complete viral genomes. Therefore, here we use CheckV to quality control the geNomad results and also to trim potential host regions left at the ends of proviruses. </p> <p>Note: This command will take about 10 minutes to complete. Again, you can continue with the results in <code>/data/precomputed/virome/checkv_results/</code>. <pre><code>checkv \\\n    end_to_end \\\n    geNomad_results/contigs_summary/contigs_virus.fna \\\n    CheckV_results \\\n    -d /data/databases/checkv-db-v1.4\n</code></pre></p> <p>The CheckV output is described here. Look into <code>CheckV_results/quality_summary.tsv</code>.</p> 1. How many proviruses do you find and how many viruses? <p>9 proviruses, 46 viruses.</p> 2. How many low, medium, and high quality viruses do we detect? How many complete viruses? How many of them have direct terminal repeats? <p>11 viruses with low-quality, 20 with medium-quality and 9 with high-quality. 15 viruses are complete. From them, 10 have direct terminal repeats (DTRs).</p> <p>Note: Depending on the project's goals, it may be advisable to select only viruses predicted to be of at least medium quality. However, for this exercise, we will proceed with all available sequences.</p> <p>Note: CheckV provides 2 separate files with the identified proviral and viral sequences. As we want to work with both of them, we combine them into a single file: </p> <pre><code>cat CheckV_results/proviruses.fna CheckV_results/viruses.fna &gt; CheckV_results/combined.fna\n</code></pre>"},{"location":"functional-annotation/viromes/#step-3-bacterial-host-assignment","title":"Step 3 - Bacterial host assignment","text":"<p>We will use iPHoP for bacterial host assignment of the viruses. Although iPHoP provides both genus- and species-level host predictions, we will focus solely on genus-level assignments. This is because iPHoP offers high-confidence predictions at the genus level (with an estimated false discovery rate of less than 10%), while the confidence decreases at the species level.</p> <p>Note: The following command can take around 1 hour. Therefore, you should continue with the results in <code>/data/precomputed/virome/iphop_results/</code>. <pre><code>mkdir iphop_results\n\niphop predict \\\n    --fa_file CheckV_results/combined.fna \\\n    --db_dir /data/databases/Aug_2023_pub_rw/ \\\n    --num_threads 8 \\\n    --out_dir iphop_results\n</code></pre></p> <p>The iPHoP output is described here. </p> <p>Note: iPHoP allows to enrich the default database with custom MAGs to improve the host assignment of the viruses.</p> <p>Look into <code>iphop_results/Host_prediction_to_genus_m90.csv</code>. By default, all virus-host pairs for which the confidence score is higher than the selected cutoff (default = 90) are included. For this exercise, consider only the top hit for each virus (prediction with highest confidence score):</p> 1. Is there any virus predicted to infect the Clostridium genus? <p>Yes, 2 viruses are predicted to infect Clostridium (CS_426 and CS_2284).</p> 2. Considering the genome completeness estimated in the previous step, which of these Clostridium phages is predicted to have a complete genome? <p>Both phages have a complete genome (with DTRs).</p>"},{"location":"functional-annotation/viromes/#step-4-functional-annotation","title":"Step 4 - Functional annotation","text":"<p>Multiple tools can be used for the functional annotation of viral genomes. Here, we will use geNomad (annotate module) to retrieve the annotations for each of the proteins in our predicted viral genomes.</p> <p>Note: The following command takes about 2 minutes. You can also continue with the results in <code>/data/precomputed/virome/genomad_annotation_results/</code>. <pre><code>genomad annotate \\\n    CheckV_results/combined.fna \\\n    geNomad_annotation_results \\\n    --cleanup \\\n    /data/databases/genomad/genomad_db/\n</code></pre></p> <p>The detailed explanation of this step can be found here. Check now the <code>geNomad_annotation_results/combined_annotate/combined_genes.tsv</code> file:</p> 1. Does any of the identified viruses use an alternative genetic code? <p>No, all the viruses use the standard genetic code (translation table 11).</p> 2. Are any of the identified viruses encoding proteins that enable integration into the bacterial genome (integrases)? <p>Yes, at least 6 viruses encode integrases (GPD_79092, ELGV_14024, CS_100, CS_659, CS_1726 and CS_2284)  </p> <p>Note: Genetic code 11 (translation table 11) is the standard code used for Bacteria, Archaea, prokaryotic viruses and chloroplast proteins.</p> Which bacteriophage are we looking for? <p>CS_2284: A predicted complete Clostridium phage, belonging to the Caudoviricetes class, that can integrate into the host genome.</p>"}]}